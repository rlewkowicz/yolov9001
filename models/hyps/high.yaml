optimizer:
  SGD:
    lr0: 0.02        # base LR
    lrf: 0.02        # final LR fraction for cosine decay
    momentum: 0.937  # SGD momentum
    warmup_momentum: 0.937   # start momentum during warmup
    warmup_epochs: 0.0     # linear warmup duration (epochs)
    warmup_bias_lr: 1   # bias-group LR at start of warmup
    nesterov: true
    weight_decay: 0.0005
    decoupled_lr:
      backbone:
        lr_scale: 1.0
      head:
        lr_scale: 1.0

# TAL & Loss
box: 7.5
cls: 1.0
dfl: 1.5
iou_type: MPDIoU
assign_mode: simota
cls_type: vfl
vfl_alpha: 1.0
vfl_gamma: 3.0

assign_radius: 3.5
assign_lambda_iou: 3.5
assign_topq: 10

# Ancillary
min_stride_box_alpha: 0.1

# Augmentations
hsv_h: 0.015
hsv_s: 0.7
hsv_v: 0.4
degrees: 4.0
translate: 0.1
scale: 0.7
fliplr: 0.5
mosaic: .9
mixup: 0.1
copy_paste: 0.3

dino:
  enabled: true
  # model_name: facebook/dinov3-vitb16-pretrain-lvd1689m
  objfor02: true
  # resolution: 640
  alpha: 0.9
  beta: 0.5
  gamma: 0.25
  # Clamp teacher share to avoid overtaking supervised loss
  share_clamp:
    enabled: true
    max: 0.4
  patience_epochs: 1
  patience_delta: 0.0
  cls_type_after_off: bce
  reg_weight_with_saliency: true
  reg_weight_floor: 0.1
  reg_weight_power: 5.0
  centroid_align: true
  centroid_weight: 0.9
  centroid_max_epochs: 3
  max_epochs: 200
  every_n: 1
  quant: int4
  distill_decay_epochs: 50
  objfor02_decay_epochs: 50
